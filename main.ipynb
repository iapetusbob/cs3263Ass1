{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS3263 Assignment 1\n",
    "\n",
    "Welcome to the CS3263 assignment 1, you will complete both the programming part and writing part in this notebook!\n",
    "\n",
    "* Group Member 1:\n",
    "    - Name:\n",
    "    - Student ID:\n",
    "\n",
    "* Group Member 2:\n",
    "    - Name:\n",
    "    - Student ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Part\n",
    "\n",
    "In the programming part, we are going to solve the searching problems in a gird maze environment. This notebook will walk you through to use the environment, to define your own agent, to solve the problems.\n",
    "\n",
    "You are expected to add your codes in the blocks noted by:\n",
    "\n",
    "```python\n",
    "'''---Your codes start here---'''\n",
    "\n",
    "'''---Your codes end here----'''\n",
    "```\n",
    "\n",
    "Let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Environment Setup\n",
    "\n",
    "To set up the programming environment, three basic packages `typer`, `typing` and `numpy` are needed. You can install them by the way you like.\n",
    "\n",
    "For example, install using `pip`:\n",
    "\n",
    "```\n",
    "pip install typer numpy\n",
    "```\n",
    "\n",
    "or install using `Anaconda`:\n",
    "\n",
    "```\n",
    "conda install typer numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typer\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Callable\n",
    "from FAIAss1.MazeEnv import Maze, MazeEnvProblem\n",
    "from FAIAss1.Agent import Agent, OnlineAgent, MCAgent\n",
    "from FAIAss1.configs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maze Environment\n",
    "\n",
    "All environments are defined in the `FAIAss1` package.\n",
    "\n",
    "- state: each state is represented as a coordinate `[x,y]` (a two-element Python **list**), where the `[0,0]` state is the lower-left corner, the x-axis is horizontal and y-axis is vertical.\n",
    "- actions: at each state, the available actions make the agent move to next grid. An action is an `int` value in Python, the meaning of all actions:\n",
    "    ```\n",
    "    0 - moving upwards\n",
    "    1 - moving downwards\n",
    "    2 - moving leftwards\n",
    "    3 - moving rightwards\n",
    "    ```\n",
    "- **Note**: the state starts from `[0,0]` not `[1,1]`, which is a bit different from problems definition in tutorials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate one maze using the maze configs\n",
    "maze_sample = Maze(width=3, height=3, walls=walls_maze1)\n",
    "# instantiate one search problem\n",
    "problem_sample = MazeEnvProblem(initial=[0, 0], goal=[2, 2], maze=maze_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Maze` class defines a maze environment, the `MazeEnvProblem` defines one problem we want to solve.\n",
    "\n",
    "`MazeEnvProblem` class methods (suppose `problem` is an instance):\n",
    "\n",
    "* `problem.actions(state)`: Return the actions that can be executed in the given state.\n",
    "* `problem.result(state, action)`: Return the state that results from executing the given action in the given state.\n",
    "* `problem.goal_test(state)`: Return True if the state is a goal.\n",
    "* `problem.path_cost(c, state1, action, state2)`: Return the cost of a solution path that arrives at state2 from state1 via action, assuming cost c to get up to state1.\n",
    "* `problem.value(state)`: Return a value for the given state. (Currently, we define the value of each state is the negative Manhattan distance between it and the goal state).\n",
    "* `problem.c(state, action, state1)`: Return a cost estimate for an agent to move from state 'state' to state 'state1', in our problem, we define the cost for any one step is 1.\n",
    "* `problem.h(state)`: Return possible cost to reach a goal for the given state, or we can call it heuristic function. Currently, we define it as the Manhattan distance between the current state and the goal state.\n",
    "\n",
    "You can understand the maze environment by running the following section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available actions of state [0,0]:\")\n",
    "for a in problem_sample.actions([0, 0]): print(action_name[a])\n",
    "\n",
    "print(\"\\nThe next state by acting 'RIGHT' action at state [0,0]:\")\n",
    "print(problem_sample.result([0, 0], 3))\n",
    "\n",
    "print(\"\\nIs [2,2] a goal state?\")\n",
    "print(problem_sample.goal_test([2, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Solving Agents\n",
    "\n",
    "The problem solving agents allow you to run search algorithms to solve the maze problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Hill Climbing Search\n",
    "\n",
    "We will design a ``searching()`` function in the ``hillclimbingAgent``.\n",
    "\n",
    "* ``hillclimbingAgent.searching(s, actions_available, result, v)``. The input of this function contains:\n",
    "    * ``s`` is the current state (list)\n",
    "    * ``actions_available`` is a list of valid actions that the agent can take at the current state ``s``.\n",
    "    * ``result(state, action)`` is a ``Callable`` function, it will return the next state given the ``state`` and ``action``. The given ``state`` is a ``list``.\n",
    "    * ``v(state)`` is a ``Callable`` function, it will return the value given the ``state``. The given ``state`` is a ``list``.  It will return an ``int`` value.\n",
    "\n",
    "You will need to fill in the code to complete the function and return the action ``a`` in the next step. The returned action ``a`` is an ``int``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hillclimbingAgent(Agent):\n",
    "    def __init__(self, problem):\n",
    "        super().__init__(problem)\n",
    "\n",
    "    def searching(self, s, actions_available, result: Callable, v: Callable):\n",
    "        '''The hill climbing algorithm\n",
    "        args:\n",
    "            ::s:: current state\n",
    "            ::actions_available:: the action you can take at current state\n",
    "            ::result:: Callable, predict the next state given the current state and action\n",
    "            ::v:: Callable, value of the states.\n",
    "        returns:\n",
    "            ::a:: actions to take next, if stop, return None\n",
    "        '''\n",
    "\n",
    "        a = None\n",
    "\n",
    "        '''---your codes start here---'''\n",
    "\n",
    "\n",
    "        '''----your codes end here----'''\n",
    "\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Your comments for your solution\n",
    "\n",
    "If you want to add any comments to your solutions, please leave it here\n",
    "\n",
    "--- your comments start here ---\n",
    "\n",
    "---- your comments end here ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Learning Real-Time A*\n",
    "\n",
    "The ``LRTAstarAgent`` has two class variable ``self.H`` and ``self.result``. **You can modify these variables in the given coding areas.**\n",
    "\n",
    "We will design a ``search()`` function and a ``cost()`` function in this class. **Note: the `search()` function here is different with the `searching()` function in `hillclimbingAgent`**.\n",
    "\n",
    "* ``LRTAstarAgent.search(s_previous, a_previous, s1, goal_test, h, actions, cost)``. The input of this function contains:\n",
    "    * ``s_previous`` is the previous state (list)\n",
    "    * ``a_previous`` the previous action (int)\n",
    "    * ``s1`` is the current state (list)\n",
    "    * ``goal_test(state)`` is a ``Callable`` function, it will test whether a given ``state`` is the goal. The given ``state`` is a list. It will return a ``boolean`` value indicating whether it is ``True`` or ``False`` that the given state is the goal state.\n",
    "    * ``h(state)`` is a ``Callable`` function, it will return the heuristic value given the ``state``. The given ``state`` is a ``list``.  It will return a ``float`` value.\n",
    "    * ``actions(state)`` is a ``Callable`` function, it will return the available actions at the given ``state``. The ``state`` is a ``list``. It will return a ``list`` of ``int``.\n",
    "    * ``cost``: the cost value.\n",
    "\n",
    "You will need to fill in the code to complete the function and return the action ``a`` in the next step. The returned action ``a`` is an ``int``.\n",
    "\n",
    "In addition, you will also need to complete the function ``cost``, which is the step that evaluate the cost to move from state s to the next state.\n",
    "* ``LRTAstarAgent.cost(s, a, h: Callable, c: Callable)``. The input of this function contains:\n",
    "    * ``s`` is the given current state (list)\n",
    "    * ``a`` is the given action (int)\n",
    "    * ``h(state)`` is a ``Callable`` function, it will return the heuristic value given the ``state``. The given ``state`` is a ``list``.  It will return a ``float`` value.\n",
    "    * ``c(s, a, s1)`` is a ``Callable`` function, it will return the cost value given the current state ``s`` (list), the action to take ``a`` (int), the next expected state ``s1`` (list). It will return a ``float`` value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRTAstarAgent(OnlineAgent):\n",
    "    def __init__(self, problem):\n",
    "        super().__init__(problem)\n",
    "        self.H = {}\n",
    "        self.result = {}\n",
    "\n",
    "    def search(self, s_previous, a_previous, s1, goal_test: Callable, h: Callable, actions: Callable, cost: Callable):\n",
    "        '''The searching algorithm of Learning Real-time A*\n",
    "        args:\n",
    "            :s_previous: previous state\n",
    "            :a_previous: previous action\n",
    "            :s1: current state\n",
    "            :goal_test: Callable, test whether a state is a goal\n",
    "            :h: Callable, heuristic function\n",
    "            :actions: Callable, return the available actions given the state\n",
    "        returns:\n",
    "            :cost: the cost value.\n",
    "        '''\n",
    "\n",
    "        a = None\n",
    "\n",
    "        '''---your codes start here---'''\n",
    "        \n",
    "        \n",
    "        '''----your codes end here----'''\n",
    "\n",
    "        return a\n",
    "\n",
    "    def cost(self, s, a, h: Callable, c: Callable):\n",
    "        '''Returns cost to move from state 's' given the action 'a'.\n",
    "        args:\n",
    "            :s: current state (list)\n",
    "            :a: current action (int)\n",
    "            :h: heuristic function (callable)\n",
    "            :c: cost function(callable)\n",
    "        returns:\n",
    "            :cost_value: the cost value to the next state (float)\n",
    "        '''\n",
    "\n",
    "        cost_value = None\n",
    "\n",
    "        '''---your codes start here---'''\n",
    "        \n",
    "        \n",
    "        '''----your codes end here----'''\n",
    "\n",
    "        return cost_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Your comments for your solution\n",
    "\n",
    "If you want to add any comments to your solutions, please leave it here\n",
    "\n",
    "--- your comments start here ---\n",
    "\n",
    "---- your comments end here ----"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Task 3: Monte Carlo Tree Search (MCTS)\n",
    "\n",
    "The ``MCTSAgent`` implements the MCTS algorithm. The `MCT_Node` class implements the node in the Monte Carlo trees, each node will keep track of the children states."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MCT_Node:\n",
    "    \"\"\"Node in the Monte Carlo search tree, keeps track of the children states.\"\"\"\n",
    "\n",
    "    def __init__(self, parent=None, act=None, state=None, record=None, U=0, N=0):\n",
    "        self.__dict__.update(parent=parent, state=state, U=U, N=N)\n",
    "        self.children = {}\n",
    "        self.record = record\n",
    "        self.act = act"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You are going to complete the `expand()`, `select` and `search()` functions.\n",
    "\n",
    "- `expand()`: this function expands the leaf node by adding all its children states.\n",
    "- `select()`: this function select a leaf node in the tree based on the `ucb` values.\n",
    "- `search()`: this function complete the search logic.\n",
    "\n",
    "**Hints**: consider recursion when you are implementing some functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Please note**: to avoid the agent jumping back and forth, and then being trapped in a small local area, we use the `self.record` to record the history states to make the agent can only step forward, which means, we will check if the next state is in the `self.record`, if it is, we will not add it to the tree. You can use the `self.record` to check if the next state is in the record.\n",
    "\n",
    "The logic of the `self.record` is implemented in the `actions()` function in the `MazeEnvProblem` class:\n",
    "\n",
    "```python\n",
    "def actions(self, state, record=None):\n",
    "\n",
    "    actions = self.maze.available_actions(state)\n",
    "\n",
    "    if record is None:\n",
    "        return actions\n",
    "    else:\n",
    "        acts = []\n",
    "        for action in actions:\n",
    "            if record[self.result(state, action)[0]][self.result(state, action)[1]] == 0:\n",
    "                acts.append(action)\n",
    "        return acts\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MCTSAgent(MCAgent):\n",
    "    def __init__(self, problem):\n",
    "        super().__init__(problem)\n",
    "        self.N = 20\n",
    "        self.maze = problem.maze\n",
    "        self.record = np.zeros((self.maze.width, self.maze.height))\n",
    "        self.H = {}\n",
    "        self.result = {}\n",
    "\n",
    "    def ucb(self, n, C=1.4):\n",
    "        ucb = np.inf if n.N == 0 else n.U / n.N + C * np.sqrt(np.log(n.parent.N) / n.N)\n",
    "        return ucb\n",
    "\n",
    "    def takeaction(self, act, record):\n",
    "        new = record.copy()\n",
    "        new[act[0]][act[1]] += 1\n",
    "        return new\n",
    "\n",
    "    def search(self, s, h: Callable, goal_test: Callable, actions: Callable, cost: Callable, is_terminal: Callable, result: Callable, utility: Callable):\n",
    "        if goal_test(s):\n",
    "            a = None\n",
    "            return a\n",
    "\n",
    "        record = self.record.copy()\n",
    "        self.record[s[0]][s[1]] += 1\n",
    "        root = MCT_Node(state=s, record=self.takeaction(s, record))\n",
    "\n",
    "        for _ in range(self.N):\n",
    "            '''---your codes start here---'''\n",
    "            \n",
    "            \n",
    "            '''----your codes end here----'''\n",
    "\n",
    "        max_state = max(root.children, key=lambda p: p.N)\n",
    "\n",
    "        return max_state.act\n",
    "\n",
    "    def select(self, n, actions: Callable):\n",
    "        \"\"\"select a leaf node in the tree\"\"\"\n",
    "        if n.children:\n",
    "            '''---your codes start here---'''\n",
    "        \n",
    "\n",
    "            '''----your codes end here----'''            \n",
    "        else:\n",
    "            return n\n",
    "\n",
    "    def expand(self, n, terminal_test: Callable, result: Callable, actions: Callable):\n",
    "        \"\"\"expand the leaf node by adding all its children states\"\"\"\n",
    "        \n",
    "        '''---your codes start here---'''\n",
    "        \n",
    "        \n",
    "        '''----your codes end here----'''\n",
    "        \n",
    "        return self.select(n, actions)\n",
    "\n",
    "    def simulate(self, child, actions: Callable, is_terminal: Callable, result: Callable, utility: Callable):\n",
    "        \"\"\"simulate the utility of current state by random picking a step\"\"\"\n",
    "        cost = 1\n",
    "        state = child.state\n",
    "        record = child.record\n",
    "        while not is_terminal(state, record):\n",
    "            action = random.choice(list(actions(state, record)))\n",
    "            state = result(state, action)\n",
    "            record = self.takeaction(state, record)\n",
    "            cost += 1\n",
    "        v = utility(state, cost)\n",
    "        return v\n",
    "\n",
    "    def backprop(self, n, utility):\n",
    "        \"\"\"passing the utility back to all parent nodes\"\"\"\n",
    "        if utility > 0:\n",
    "            n.U += utility\n",
    "        n.N += 1\n",
    "        if n.parent:\n",
    "            self.backprop(n.parent, utility)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Your comments for your solution\n",
    "\n",
    "If you want to add any comments to your solutions, please leave it here\n",
    "\n",
    "--- your comments start here ---\n",
    "\n",
    "---- your comments end here ----"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Your Agents\n",
    "\n",
    "Now we can run the agents, you don't have to modify any codes in the following section, just run to test your agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_list = {\n",
    "    'hill_climbing': hillclimbingAgent,\n",
    "    'lrtastar': LRTAstarAgent,\n",
    "    'MCTS': MCTSAgent,\n",
    "}\n",
    "\n",
    "\n",
    "def print_path(path):\n",
    "    for p in path:\n",
    "        action = p[-1]\n",
    "        if action is not None:\n",
    "            print(\"state: {}, action: {}\".format(p[0], action_name[action]))\n",
    "        else:\n",
    "            print(\"state: {}\".format(p[0]))\n",
    "\n",
    "\n",
    "def run(problem, model_name: str, num_steps: int):\n",
    "    path = []\n",
    "    # Initialize mazes and problems objects\n",
    "\n",
    "    assert model_name in agent_list.keys(), \"Not available algorithm!\"\n",
    "\n",
    "    agent = agent_list[model_name](problem)\n",
    "    state = problem.initial\n",
    "    for _ in range(num_steps):\n",
    "        a = agent(state, problem.h)\n",
    "        path.append((state, a))\n",
    "        if a is None:\n",
    "            break\n",
    "        state_next = problem.result(state, a)\n",
    "        state = state_next\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have prepared three simple mazes for you to test your codes. Now we can use the `run` function to test your codes. The `run` function takes in three arguments:\n",
    "\n",
    "* `problem`: please use the three sample mazes.\n",
    "* `model_name`: a string to indicate which algorithm you want to run:\n",
    "    - `'hill_climbing'`: for the task 1.\n",
    "    - `'lrtastar'`: for the task 2.\n",
    "    - `'MCTS'`: for the task 3.\n",
    "* `num_steps`: number of steps to run the algorithm\n",
    "\n",
    "**Please reserve your running results when you submit your codes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze1 = Maze(width=3, height=3, walls=walls_maze1)\n",
    "problem1 = MazeEnvProblem(initial=[0, 0], goal=[2, 2], maze=maze1)\n",
    "\n",
    "maze2 = Maze(width=2, height=3, walls=walls_maze2)\n",
    "problem2 = MazeEnvProblem(initial=[0, 0], goal=[1, 2], maze=maze2)\n",
    "\n",
    "maze3 = Maze(width=4, height=3, walls=walls_maze3)\n",
    "problem3 = MazeEnvProblem(initial=[0, 0], goal=[3, 2], maze=maze3)\n",
    "\n",
    "print(\"========== Task 1: Hill Climbing ==========\")\n",
    "\n",
    "print(\"----- Maze 1 -----\")\n",
    "\n",
    "path = run(problem1, 'hill_climbing', 100)\n",
    "print_path(path)\n",
    "\n",
    "print(\"----- Maze 2 -----\")\n",
    "\n",
    "path = run(problem2, 'hill_climbing', 100)\n",
    "print_path(path)\n",
    "\n",
    "print(\"----- Maze 3 -----\")\n",
    "\n",
    "path = run(problem3, 'hill_climbing', 100)\n",
    "print_path(path)\n",
    "\n",
    "print(\"========== Task 2: Learning Real-Time A* ==========\")\n",
    "\n",
    "print(\"----- Maze 1 -----\")\n",
    "\n",
    "path = run(problem1, 'lrtastar', 100)\n",
    "print_path(path)\n",
    "\n",
    "print(\"----- Maze 2 -----\")\n",
    "\n",
    "path = run(problem2, 'lrtastar', 100)\n",
    "print_path(path)\n",
    "\n",
    "print(\"----- Maze 3 -----\")\n",
    "\n",
    "path = run(problem3, 'lrtastar', 100)\n",
    "print_path(path)\n",
    "\n",
    "print(\"========== Task 3: Monte Carlo Tree Search ==========\")\n",
    "\n",
    "print(\"----- Maze 1 -----\")\n",
    "\n",
    "path = run(problem1, 'MCTS', 100)\n",
    "print_path(path)\n",
    "\n",
    "print(\"----- Maze 2 -----\")\n",
    "\n",
    "path = run(problem2, 'MCTS', 100)\n",
    "print_path(path)\n",
    "\n",
    "print(\"----- Maze 3 -----\")\n",
    "\n",
    "path = run(problem3, 'MCTS', 100)\n",
    "print_path(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission\n",
    "\n",
    "**! Important**: Please write your code in **the given area** of **BOTH** the current Notebook and [the `programming.py` file](./programming.py).\n",
    "\n",
    "The `programming.py` file is **for our evaluation**, you just need to copy your solutions from the above sections to the script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
